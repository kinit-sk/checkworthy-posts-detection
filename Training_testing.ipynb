{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYDStgLYhYCQ2jpYaO+efq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install flair==0.7"],"metadata":{"id":"PqAUE6NoQKoR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# flair version 0.7 code to train the model for one class two labels, to launch the training and then three files must be prepared (train.csv, dev.csv and test.scv)\n","from torch.optim.adam import Adam\n","from flair.datasets import CSVClassificationCorpus\n","from flair.data import Corpus\n","from flair.embeddings import TransformerDocumentEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer\n","\n","data_folder = '/content'\n","\n","column_name_map = {0: 'text', 1: 'label_fact'}\n","\n","# 1. get the corpus\n","corpus: Corpus = CSVClassificationCorpus(data_folder,\n","                                         column_name_map,\n","                                         # in_memory=False\n","                                         skip_header=True,\n","                                         # delimiter='\\t', tab-separated files\n",")\n","\n","# 1. get the corpus\n","#corpus: Corpus = TREC_6()\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()\n","\n","# 3. initialize transformer document embeddings (many models are available)\n","#document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('distilbert-base-multilingual-cased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('bert-base-multilingual-cased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('bert-large-cased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('bert-large-uncased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('roberta-large', fine_tune=True)\n","document_embeddings = TransformerDocumentEmbeddings('xlm-roberta-base', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('xlm-roberta-large', fine_tune=True)\n","\n","# 4. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","\n","# 5. initialize the text classifier trainer with Adam optimizer\n","trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n","\n","# 6. start the training\n","trainer.train('resources/taggers/trec',\n","              learning_rate=3e-5, # use very small learning rate\n","              mini_batch_size=32, #\n","              #embeddings_storage_mode='cpu',\n","              embeddings_storage_mode='gpu',\n","              #mini_batch_chunk_size=1, # optionally set this if transformer is too much for your machine\n","              max_epochs=5, #10, # terminate after 5 epochs\n",")"],"metadata":{"id":"aNd8vU6OObHX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# flair version 0.7 multi-label, to launch the training and then three files must be prepared (train.csv, dev.csv and test.scv)\n","from torch.optim.adam import Adam\n","from flair.datasets import CSVClassificationCorpus\n","from flair.data import Corpus\n","from flair.embeddings import TransformerDocumentEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer\n","\n","data_folder = '/content'\n","\n","column_name_map = {0: 'text', 1: 'label_fact', 2: 'label_harm'}\n","\n","# 1. get the corpus\n","corpus: Corpus = CSVClassificationCorpus(data_folder,\n","                                         column_name_map,\n","                                         skip_header=True,\n",")\n","\n","# 1. get the corpus\n","#corpus: Corpus = TREC_6()\n","\n","# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()\n","\n","# 3. initialize transformer document embeddings (many models are available)\n","#document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('distilbert-base-multilingual-cased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('bert-base-multilingual-cased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('bert-large-cased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('bert-large-uncased', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('roberta-large', fine_tune=True)\n","document_embeddings = TransformerDocumentEmbeddings('xlm-roberta-base', fine_tune=True)\n","#document_embeddings = TransformerDocumentEmbeddings('xlm-roberta-large', fine_tune=True)\n","\n","# 4. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n","\n","# 5. initialize the text classifier trainer with Adam optimizer\n","trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n","\n","# 6. start the training\n","trainer.train('resources/taggers/trec',\n","              learning_rate=3e-5, # use very small learning rate\n","              mini_batch_size=32, #\n","              #embeddings_storage_mode='cpu',\n","              embeddings_storage_mode='gpu',\n","              #mini_batch_chunk_size=1, # optionally set this if transformer is too much for your machine\n","              max_epochs=5, #10, # terminate after 5 epochs\n",")"],"metadata":{"id":"uvxC8iyYz-ri"},"execution_count":null,"outputs":[]}]}